# -*- coding: utf-8 -*-
"""BloodCellClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oQ8e769rUtgrJ0wbAt4By87WMr9FmRx2

# **Download Dataset From Kaggle**
"""

from google.colab import drive

drive.mount('/content/drive')

! mkdir -p ~/.kaggle/

! cp /content/drive/MyDrive/Kaggle_API/kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download unclesamulus/blood-cells-image-dataset

import os
import zipfile

zip_file = "/content/blood-cells-image-dataset.zip"
extract_folder = "/content/blood-cells-image-dataset"
with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)
os.listdir(extract_folder)

for root, dirs, files in os.walk(extract_folder):
    print(f"Directory: {root}")
    for file in files[:5]:
        print(f"  - {file}")

"""# **Data Exploration**"""

import os
from PIL import Image
import matplotlib.pyplot as plt

dataset_path = "/content/blood-cells-image-dataset/bloodcells_dataset"

image_paths = []
labels = []

for category in os.listdir(dataset_path):
    category_path = os.path.join(dataset_path, category)

    if os.path.isdir(category_path):
        for img_name in os.listdir(category_path):
            if img_name.endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(category_path, img_name))
                labels.append(category)

print(f"ðŸ“¸ {len(image_paths)} immagini caricate da {len(set(labels))} classi.")

image = Image.open(image_paths[0])
plt.imshow(image)
plt.title(f"Classe: {labels[0]}")
plt.axis("off")
plt.show()

import pandas as pd
class_counts = {}

for category in os.listdir(dataset_path):
    category_path = os.path.join(dataset_path, category)

    if os.path.isdir(category_path):
        num_images = len([img for img in os.listdir(category_path) if img.endswith(('.png', '.jpg', '.jpeg'))])
        class_counts[category] = num_images


df = pd.DataFrame(list(class_counts.items()), columns=["Class", "Number of Images"])


print(df)

plt.figure(figsize=(10, 5))
plt.bar(df["Class"], df["Number of Images"], color='skyblue')
plt.xlabel("Class")
plt.ylabel("Number of Images")
plt.title("Dataset Class Distribution")
plt.xticks(rotation=45)
plt.show()

import random
import numpy as np
import pandas as pd
import cv2

X = []
y = []

dataset_path = "/content/blood-cells-image-dataset/bloodcells_dataset"

image_size = (64, 64)  # Ridimensioniamo per velocizzare il modello



for cls in os.listdir(dataset_path):
    class_dir = os.path.join(dataset_path, cls)
    label = cls

    for img_name in os.listdir(class_dir):
        img_path = os.path.join(class_dir, img_name)
        img = cv2.imread(img_path)
        img = cv2.resize(img, image_size)

        X.append(img)
        y.append(label)


X = np.array(X, dtype=np.float32) / 255.0
y = np.array(y)

print(f"ðŸ“Š Dataset : {X.shape[0]} images, size {X.shape[1]}")

y.shape

from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_categorical = to_categorical(y_encoded, num_classes=len(np.unique(y_encoded))) #one-hot encoding
print(f" Class coded: {label_encoder.classes_}")

y_encoded

y_categorical[0]

X_temp, X_test, y_temp, y_test = train_test_split(
    X, y_categorical, test_size=0.3, random_state=42, stratify=y_categorical, shuffle=True
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp, shuffle=True
)
print(f"Train set: {X_train.shape[0]} images")
print(f"Validation set: {X_val.shape[0]} images")
print(f"Test set: {X_test.shape[0]} images")

y_train.shape

y_train[0]

X_train[0]

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_encoded),
    y=y_encoded
)
class_weight_dict = {i: w for i, w in enumerate(class_weights)}

print(f"Class Weights:{class_weight_dict}")

print(X_train.shape)
print(X_val.shape)
print(X_test.shape)

print(y_train.shape)
print(y_val.shape)
print(y_test.shape)

"""# **LogisticRegression Model**"""

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

y_train_labels = np.argmax(y_train, axis=1)
y_val_labels = np.argmax(y_val, axis=1)
y_test_labels = np.argmax(y_test, axis=1)

X_train_flattened = X_train.reshape(X_train.shape[0], -1)
X_val_flattened = X_val.reshape(X_val.shape[0], -1)
X_test_flattened = X_test.reshape(X_test.shape[0], -1)

log_reg = LogisticRegression(max_iter=10000,solver='lbfgs', multi_class='multinomial', n_jobs=-1)
log_reg.fit(X_train_flattened, y_train_labels)

y_pred = log_reg.predict(X_test_flattened)

print("Accuracy:", accuracy_score(y_test_labels, y_pred))
print("Classification Report:\n", classification_report(y_test_labels, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Calcoliamo la matrice di confusione
cm = confusion_matrix(y_test_labels, y_pred)

# Creiamo una heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=range(8), yticklabels=range(8))
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""# **Convolutional Neural Network Model**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam

model = tf.keras.Sequential([
    tf.keras.Input(shape=( 64, 64, 3)),

    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(256, (3, 3), activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(len(np.unique(y_encoded)), activation='softmax')
 ])

early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

model.compile(
    optimizer=Adam(learning_rate=0.00001),
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)

model.summary()

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=50,
    class_weight=class_weight_dict,
    batch_size=16,
    callbacks=[early_stop]
)

plt.figure(figsize=(12, 5))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title("Accuracy durante il training")

# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title("Loss durante il training")

plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

y_test_pred = model.predict(X_test)
y_test_pred_classes = np.argmax(y_test_pred, axis=1)
y_test_true_classes = np.argmax(y_test, axis=1)


conf_matrix = confusion_matrix(y_test_true_classes, y_test_pred_classes)

plt.figure(figsize=(10, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel("Predicted")
plt.ylabel("Real")
plt.title("Confusion Matrix - Test Set")
plt.show()

test_loss, test_acc = model.evaluate(X_test, y_test)

from sklearn.metrics import classification_report

# Predizioni sul test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Report delle metriche
print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))

import random

# Scegliamo un'immagine casuale dal Test Set
random_idx = random.randint(0, len(X_test) - 1)
img = X_test[random_idx]

# Previsione
prediction = model.predict(np.expand_dims(img, axis=0))
predicted_class = label_encoder.classes_[np.argmax(prediction)]

true_class = label_encoder.classes_[np.argmax(y_test[random_idx])]

plt.imshow(img)
plt.title(f"Predicted: {predicted_class} | Real: {true_class}")
plt.axis("off")
plt.show()

import random
import numpy as np
import matplotlib.pyplot as plt

# Numero di immagini da visualizzare
num_images = 20  # Cambia questo numero in base al numero di immagini che vuoi visualizzare
rows = 5  # Numero di righe
cols = num_images // rows  # Numero di colonne, calcolato in base al numero di immagini e righe

# Selezioniamo indici casuali dal test set
random_indices = random.sample(range(len(X_test)), num_images)

# Creiamo la figura con piÃ¹ subplot
fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))

# Flatten se axes Ã¨ un array 2D (necessario per iterare facilmente)
axes = axes.flatten()

for i, idx in enumerate(random_indices):
    img = X_test[idx]

    # Previsione
    prediction = model.predict(np.expand_dims(img, axis=0))
    predicted_class = label_encoder.classes_[np.argmax(prediction)]

    # Valore reale
    true_class = label_encoder.classes_[np.argmax(y_test[idx])]

    # Visualizzazione
    axes[i].imshow(img)
    axes[i].set_title(f"Predicted: {predicted_class}\nTrue: {true_class}", fontsize=10)
    axes[i].axis("off")

# Rimuoviamo eventuali subplot vuoti
for j in range(i + 1, len(axes)):
    axes[j].axis("off")

plt.tight_layout()
plt.show()